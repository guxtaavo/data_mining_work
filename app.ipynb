{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c4f7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de Exercícios de Mineração de Dados\n",
    "# Gustavo Nunes Lopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13a35714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino original: 143  | Treino limpo: 134\n",
      "Teste original : 28  | Teste limpo : 25\n",
      "\n",
      "===== QUESTÃO 1A =====\n",
      "Acurácia NN: 56.00%\n",
      "Acurácia Rocchio: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Questão 1\n",
    "# A)\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def remove_incomplete_data(data: list):\n",
    "    \"\"\"\n",
    "    Remover dados faltantes (-100) de uma lista de listas.\n",
    "    Só adiciona à lista se todos os valores forem válidos.\n",
    "    \n",
    "    :param data: Description\n",
    "    :type data: list\n",
    "    \"\"\"\n",
    "    cleaned_data = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j] == -100:\n",
    "                break\n",
    "        else:\n",
    "            cleaned_data.append(data[i])\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "def split_X_y(data: list):\n",
    "    \"\"\"\n",
    "    Separa os dados em atributos (X) e rótulos (y).\n",
    "    \n",
    "    Args:\n",
    "        data (list): Lista de listas com os dados.\n",
    "\n",
    "    Returns:\n",
    "        X (np.array): Matriz de atributos.\n",
    "        y (np.array): Vetor de rótulos.\n",
    "    \"\"\"\n",
    "    X = np.array([row[:7] for row in data], dtype=float)\n",
    "    y = np.array([row[7] for row in data])  # label\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calcula a acurácia entre os valores reais e previstos.\n",
    "\n",
    "    Args:\n",
    "        actual (List): Valores reais.\n",
    "        predicted (List): Valores previstos.\n",
    "\n",
    "    Returns:\n",
    "        float: Acurácia em porcentagem.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(actual) * 100.0\n",
    "\n",
    "def rocchio_train(X_train, y_train):\n",
    "    centroids = {}\n",
    "    classes = np.unique(y_train)\n",
    "\n",
    "    for c in classes:\n",
    "        Xc = X_train[y_train == c]\n",
    "        centroids[c] = np.mean(Xc, axis=0)  # vetor de 7 dimensões\n",
    "    return centroids\n",
    "\n",
    "def rocchio_predict(centroids, X_test):\n",
    "    classes = list(centroids.keys())\n",
    "    y_pred = []\n",
    "\n",
    "    for x in X_test:\n",
    "        best_class = None\n",
    "        best_dist = None\n",
    "\n",
    "        for c in classes:\n",
    "            d = euclidean_distance(x, centroids[c])\n",
    "            if best_dist is None or d < best_dist:\n",
    "                best_dist = d\n",
    "                best_class = c\n",
    "\n",
    "        y_pred.append(best_class)\n",
    "\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Distância Euclidiana\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "\n",
    "def nn_predict(X_train, y_train, X_test):\n",
    "    y_pred = []\n",
    "\n",
    "    for x in X_test:\n",
    "        best_dist = None\n",
    "        best_label = None\n",
    "\n",
    "        for i in range(len(X_train)):\n",
    "            d = euclidean_distance(x, X_train[i])\n",
    "\n",
    "            if best_dist is None or d < best_dist:\n",
    "                best_dist = d\n",
    "                best_label = y_train[i]\n",
    "\n",
    "        y_pred.append(best_label)\n",
    "\n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "# Carregando os arquivos de texto\n",
    "nebulosa_path_train = pathlib.Path().absolute() / 'db' / 'nebulosa_train.txt'\n",
    "nebulosa_path_test = pathlib.Path().absolute() / 'db' / 'nebulosa_test.txt'\n",
    "\n",
    "# Lendo os arquivos\n",
    "with open(nebulosa_path_train, 'r') as file:\n",
    "    nebulosa_train = file.read().split()\n",
    "    new_nebulosa_train = []\n",
    "    for i in range(0, len(nebulosa_train), 8):\n",
    "        new_nebulosa_train.append(nebulosa_train[i:i+8])\n",
    "\n",
    "    for i in range(len(new_nebulosa_train)):\n",
    "        for j in range(len(new_nebulosa_train[i])):\n",
    "            if j != 7:\n",
    "                new_nebulosa_train[i][j] = float(new_nebulosa_train[i][j])\n",
    "\n",
    "# app\n",
    "with open(nebulosa_path_test, 'r') as file:\n",
    "    nebulosa_test = file.read().split()\n",
    "    new_nebulosa_test = []\n",
    "    for i in range(0, len(nebulosa_test), 8):\n",
    "        new_nebulosa_test.append(nebulosa_test[i:i+8])\n",
    "\n",
    "    for i in range(len(new_nebulosa_test)):\n",
    "        for j in range(len(new_nebulosa_test[i])):\n",
    "            if j != 7:\n",
    "                new_nebulosa_test[i][j] = float(new_nebulosa_test[i][j])\n",
    "\n",
    "nebulosa_train_cleaned = remove_incomplete_data(new_nebulosa_train)\n",
    "nebulosa_test_cleaned = remove_incomplete_data(new_nebulosa_test)\n",
    "    \n",
    "print(\"Treino original:\", len(new_nebulosa_train), \" | Treino limpo:\", len(nebulosa_train_cleaned))\n",
    "print(\"Teste original :\", len(new_nebulosa_test),  \" | Teste limpo :\", len(nebulosa_test_cleaned))\n",
    "\n",
    "X_train, y_train = split_X_y(nebulosa_train_cleaned)\n",
    "X_test, y_test   = split_X_y(nebulosa_test_cleaned)\n",
    "\n",
    "print(\"\\n===== QUESTÃO 1A =====\")\n",
    "\n",
    "# ---- NN ----\n",
    "y_pred_nn = nn_predict(X_train, y_train, X_test)\n",
    "acc_nn = accuracy_metric(y_test, y_pred_nn)\n",
    "print(f\"Acurácia NN: {acc_nn:.2f}%\")\n",
    "\n",
    "# ---- Rocchio ----\n",
    "centroids = rocchio_train(X_train, y_train)\n",
    "y_pred_rocchio = rocchio_predict(centroids, X_test)\n",
    "acc_rocchio = accuracy_metric(y_test, y_pred_rocchio)\n",
    "print(f\"Acurácia Rocchio: {acc_rocchio:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f61d6073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== QUESTÃO 1B =====\n",
      "Acurácia NN: 60.00%\n",
      "Acurácia Rocchio: 4.00%\n"
     ]
    }
   ],
   "source": [
    "# Questão 1\n",
    "# B)\n",
    "\n",
    "# Para remover outliers usando o método do IQR\n",
    "def clip_outliers_iqr(X_train, X_test, k=1.5):\n",
    "    Q1 = np.percentile(X_train, 25, axis=0)\n",
    "    Q3 = np.percentile(X_train, 75, axis=0)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower = Q1 - k * IQR\n",
    "    upper = Q3 + k * IQR\n",
    "\n",
    "    X_train_clipped = np.clip(X_train, lower, upper)\n",
    "    X_test_clipped  = np.clip(X_test,  lower, upper)\n",
    "\n",
    "    return X_train_clipped, X_test_clipped\n",
    "\n",
    "# Normalização Min-Max\n",
    "def minmax_normalize(X_train, X_test):\n",
    "    min_val = np.min(X_train, axis=0)\n",
    "    max_val = np.max(X_train, axis=0)\n",
    "\n",
    "    X_train_scaled = (X_train - min_val) / (max_val - min_val)\n",
    "    X_test_scaled  = (X_test  - min_val) / (max_val - min_val)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "X_train, y_train = split_X_y(nebulosa_train_cleaned)\n",
    "X_test, y_test   = split_X_y(nebulosa_test_cleaned)\n",
    "\n",
    "print(\"===== QUESTÃO 1B =====\")\n",
    "\n",
    "# Outliers\n",
    "X_train_clp, X_test_clp = clip_outliers_iqr(X_train, X_test)\n",
    "\n",
    "# Min–Max\n",
    "X_train_mm, X_test_mm = minmax_normalize(X_train_clp, X_test_clp)\n",
    "\n",
    "# ---- NN ----\n",
    "y_pred_nn_mm = nn_predict(X_train_mm, y_train, X_test_mm)\n",
    "acc_nn_mm = accuracy_metric(y_test, y_pred_nn_mm)\n",
    "print(f\"Acurácia NN: {acc_nn_mm:.2f}%\")\n",
    "\n",
    "# ---- Rocchio ----\n",
    "centroids_mm = rocchio_train(X_train_mm, y_train)\n",
    "y_pred_rocchio_mm = rocchio_predict(centroids_mm, X_test_mm)\n",
    "acc_rocchio_mm = accuracy_metric(y_test, y_pred_rocchio_mm)\n",
    "print(f\"Acurácia Rocchio: {acc_rocchio_mm:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc226593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 1\n",
    "# C)\n",
    "\n",
    "# Os resultados obtidos na questão 1B mostram que uma aplicação de técnicas de pré-processamento ajudam a melhorar a acurácia dos classificadores NN e Rocchio.\n",
    "# Isso se deve ao fato de que a remoção de outliers reduz o impacto de valores extremos que podem distorcer a análise dos dados, bem como utilizar os valores normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18f24e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== QUESTÃO 2A =====\n",
      "Acurácia NN (implementação própria):  89.9497487437186\n",
      "Acurácia NN (scikit-learn): 89.9497487437186\n"
     ]
    }
   ],
   "source": [
    "# Questão 2\n",
    "# A)\n",
    "\n",
    "import spacy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tweets_path = pathlib.Path().absolute() / 'db' / 'Tweets_Mg.csv'\n",
    "df = pd.read_csv(tweets_path)\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "def embeddings_generator(textos):\n",
    "    embeddings = []\n",
    "    for doc in nlp.pipe(textos, batch_size=50):\n",
    "        embeddings.append(doc.vector)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "print(\"===== QUESTÃO 2A =====\")\n",
    "\n",
    "X = embeddings_generator(df[\"Text\"].astype(str))\n",
    "y = df[\"Classificacao\"].values\n",
    "\n",
    "X_train = X[:8000]\n",
    "y_train = y[:8000]\n",
    "\n",
    "X_test = X[8000:]\n",
    "y_test = y[8000:]\n",
    "\n",
    "y_pred = nn_predict(X_train, y_train, X_test)\n",
    "\n",
    "accuracy = accuracy_metric(y_test, y_pred)\n",
    "print(\"Acurácia NN (implementação própria): \", accuracy)\n",
    "\n",
    "# Agora utilizando o scikit-learn\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1) # k=5 por padrão, então pra ficar igual à nossa implementação \n",
    "# usamos k=1\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_sklearn = knn.predict(X_test)\n",
    "\n",
    "accuracy_scikit_learn = accuracy_score(y_test, y_pred_sklearn) * 100\n",
    "\n",
    "print(\"Acurácia NN (scikit-learn):\", accuracy_scikit_learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 2\n",
    "# A) (Continuação)\n",
    "\n",
    "# A acurácia obtida utilizando a implementaçlão manual é igual a utilizando \n",
    "# a biblioteca scikit-learn, pois ambos os métodos utilizam o mesmo algoritmo. A diferença\n",
    "# é que a minha implementação manual foi feita pra utilizar apenas k=1, enquanto a biblioteca\n",
    "# scikit-learn permite escolher o valor de k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a07f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 2\n",
    "# B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "613b5d37",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'delim_whitespace'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Questão 3\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# A)\u001b[39;00m\n\u001b[32m      4\u001b[39m path_auto_mpg = pathlib.Path().absolute() / \u001b[33m'\u001b[39m\u001b[33mdb\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mauto-mpg\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mauto-mpg.data\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_auto_mpg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelim_whitespace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m===== QUESTÃO 3A =====\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[31mTypeError\u001b[39m: read_csv() got an unexpected keyword argument 'delim_whitespace'"
     ]
    }
   ],
   "source": [
    "# Questão 3\n",
    "# A)\n",
    "\n",
    "path_auto_mpg = pathlib.Path().absolute() / 'db' / 'auto-mpg' / 'auto-mpg.data'\n",
    "pd.read_csv(path_auto_mpg, delim_whitespace=True, header=None,)\n",
    "\n",
    "print(\"===== QUESTÃO 3A =====\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 3\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 3\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95609a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 4\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 4\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 4\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c5e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 4\n",
    "# D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d96387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 5\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261de58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 5\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeee12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 5\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e765f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 6\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a32bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 6\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 6\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ecc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 7\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 7\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26946504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 7\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35025bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb78594",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### QUESTÕES TEÓRICAS #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2972556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 1\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 1\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 1\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
