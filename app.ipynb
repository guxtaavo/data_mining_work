{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c4f7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de Exercícios de Mineração de Dados\n",
    "# Gustavo Nunes Lopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13a35714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino original: 143  | Treino limpo: 134\n",
      "Teste original : 28  | Teste limpo : 25\n",
      "\n",
      "===== QUESTÃO 1A =====\n",
      "Acurácia NN: 56.00%\n",
      "Acurácia Rocchio: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Questão 1\n",
    "# A)\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def remove_incomplete_data(data: list):\n",
    "    \"\"\"\n",
    "    Remover dados faltantes (-100) de uma lista de listas.\n",
    "    Só adiciona à lista se todos os valores forem válidos.\n",
    "    \"\"\"\n",
    "    cleaned_data = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j] == -100:\n",
    "                break\n",
    "        else:\n",
    "            cleaned_data.append(data[i])\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "def split_X_y(data: list):\n",
    "    \"\"\"\n",
    "    Separa os dados em atributos (X) e rótulos (y).\n",
    "    \"\"\"\n",
    "    X = np.array([row[:7] for row in data], dtype=float)\n",
    "    y = np.array([row[7] for row in data])  # label\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calcula a acurácia entre os valores reais e previstos.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(actual) * 100.0\n",
    "\n",
    "def rocchio_train(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Treina o classificador Rocchio calculando os centróides para cada classe.\n",
    "    \"\"\"\n",
    "    centroids = {}\n",
    "    classes = np.unique(y_train)\n",
    "\n",
    "    for c in classes:\n",
    "        Xc = X_train[y_train == c]\n",
    "        centroids[c] = np.mean(Xc, axis=0)  # vetor de 7 dimensões\n",
    "    return centroids\n",
    "\n",
    "def rocchio_predict(centroids, X_test):\n",
    "    \"\"\" \n",
    "    Faz previsões usando o classificador Rocchio.\n",
    "    \"\"\"   \n",
    "    classes = list(centroids.keys())\n",
    "    y_pred = []\n",
    "\n",
    "    for x in X_test:\n",
    "        best_class = None\n",
    "        best_dist = None\n",
    "\n",
    "        for c in classes:\n",
    "            d = euclidean_distance(x, centroids[c])\n",
    "            if best_dist is None or d < best_dist:\n",
    "                best_dist = d\n",
    "                best_class = c\n",
    "\n",
    "        y_pred.append(best_class)\n",
    "\n",
    "    return np.array(y_pred)\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calcula a distância euclidiana entre dois pontos. \n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "\n",
    "def nn_predict(X_train, y_train, X_test):\n",
    "    \"\"\" \n",
    "    Faz previsões usando o classificador Nearest Neighbor (NN).\n",
    "    \"\"\"\n",
    "    y_pred = []\n",
    "\n",
    "    for x in X_test:\n",
    "        best_dist = None\n",
    "        best_label = None\n",
    "\n",
    "        for i in range(len(X_train)):\n",
    "            d = euclidean_distance(x, X_train[i])\n",
    "\n",
    "            if best_dist is None or d < best_dist:\n",
    "                best_dist = d\n",
    "                best_label = y_train[i]\n",
    "\n",
    "        y_pred.append(best_label)\n",
    "\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Carregando os arquivos de texto\n",
    "nebulosa_path_train = pathlib.Path().absolute() / 'db' / 'nebulosa_train.txt'\n",
    "nebulosa_path_test = pathlib.Path().absolute() / 'db' / 'nebulosa_test.txt'\n",
    "\n",
    "# Lendo os arquivos\n",
    "with open(nebulosa_path_train, 'r') as file:\n",
    "    nebulosa_train = file.read().split()\n",
    "    new_nebulosa_train = []\n",
    "    for i in range(0, len(nebulosa_train), 8):\n",
    "        new_nebulosa_train.append(nebulosa_train[i:i+8])\n",
    "\n",
    "    for i in range(len(new_nebulosa_train)):\n",
    "        for j in range(len(new_nebulosa_train[i])):\n",
    "            if j != 7:\n",
    "                new_nebulosa_train[i][j] = float(new_nebulosa_train[i][j])\n",
    "\n",
    "\n",
    "# Main\n",
    "with open(nebulosa_path_test, 'r') as file:\n",
    "    nebulosa_test = file.read().split()\n",
    "    new_nebulosa_test = []\n",
    "    for i in range(0, len(nebulosa_test), 8):\n",
    "        new_nebulosa_test.append(nebulosa_test[i:i+8])\n",
    "\n",
    "    for i in range(len(new_nebulosa_test)):\n",
    "        for j in range(len(new_nebulosa_test[i])):\n",
    "            if j != 7:\n",
    "                new_nebulosa_test[i][j] = float(new_nebulosa_test[i][j])\n",
    "\n",
    "nebulosa_train_cleaned = remove_incomplete_data(new_nebulosa_train)\n",
    "nebulosa_test_cleaned = remove_incomplete_data(new_nebulosa_test)\n",
    "    \n",
    "print(\"Treino original:\", len(new_nebulosa_train), \" | Treino limpo:\", len(nebulosa_train_cleaned))\n",
    "print(\"Teste original :\", len(new_nebulosa_test),  \" | Teste limpo :\", len(nebulosa_test_cleaned))\n",
    "\n",
    "X_train, y_train = split_X_y(nebulosa_train_cleaned)\n",
    "X_test, y_test   = split_X_y(nebulosa_test_cleaned)\n",
    "\n",
    "print(\"\\n===== QUESTÃO 1A =====\")\n",
    "\n",
    "# ---- NN ----\n",
    "y_pred_nn = nn_predict(X_train, y_train, X_test)\n",
    "acc_nn = accuracy_metric(y_test, y_pred_nn)\n",
    "print(f\"Acurácia NN: {acc_nn:.2f}%\")\n",
    "\n",
    "# ---- Rocchio ----\n",
    "centroids = rocchio_train(X_train, y_train)\n",
    "y_pred_rocchio = rocchio_predict(centroids, X_test)\n",
    "acc_rocchio = accuracy_metric(y_test, y_pred_rocchio)\n",
    "print(f\"Acurácia Rocchio: {acc_rocchio:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f61d6073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== QUESTÃO 1B =====\n",
      "Acurácia NN: 64.00%\n",
      "Acurácia Rocchio: 4.00%\n"
     ]
    }
   ],
   "source": [
    "# Questão 1\n",
    "# B)\n",
    "\n",
    "def clip_outliers_iqr(X_train, X_test, k=1.5):\n",
    "    \"\"\"\n",
    "    Para remover outliers usando o método do IQR.\n",
    "    Referência: https://www.geeksforgeeks.org/data-science/detect-and-remove-the-outliers-using-python/\n",
    "    \"\"\"\n",
    "    Q1 = np.percentile(X_train, 25, axis=0, method='midpoint')\n",
    "    Q3 = np.percentile(X_train, 75, axis=0, method='midpoint')\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower = Q1 - k * IQR\n",
    "    upper = Q3 + k * IQR\n",
    "\n",
    "    X_train_clipped = np.clip(X_train, lower, upper)\n",
    "    X_test_clipped  = np.clip(X_test,  lower, upper)\n",
    "\n",
    "    return X_train_clipped, X_test_clipped\n",
    "\n",
    "def minmax_normalize(X_train, X_test):\n",
    "    \"\"\" \n",
    "    Normaliza os dados usando a técnica Min-Max.\n",
    "    \"\"\"\n",
    "    min_val = np.min(X_train, axis=0)\n",
    "    max_val = np.max(X_train, axis=0)\n",
    "\n",
    "    X_train_scaled = (X_train - min_val) / (max_val - min_val)\n",
    "    X_test_scaled  = (X_test  - min_val) / (max_val - min_val)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "X_train, y_train = split_X_y(nebulosa_train_cleaned)\n",
    "X_test, y_test   = split_X_y(nebulosa_test_cleaned)\n",
    "\n",
    "# Main\n",
    "\n",
    "print(\"===== QUESTÃO 1B =====\")\n",
    "\n",
    "# Outliers\n",
    "X_train_clp, X_test_clp = clip_outliers_iqr(X_train, X_test)\n",
    "\n",
    "# Min–Max\n",
    "X_train_mm, X_test_mm = minmax_normalize(X_train_clp, X_test_clp)\n",
    "\n",
    "# ---- NN ----\n",
    "y_pred_nn_mm = nn_predict(X_train_mm, y_train, X_test_mm)\n",
    "acc_nn_mm = accuracy_metric(y_test, y_pred_nn_mm)\n",
    "print(f\"Acurácia NN: {acc_nn_mm:.2f}%\")\n",
    "\n",
    "# ---- Rocchio ----\n",
    "centroids_mm = rocchio_train(X_train_mm, y_train)\n",
    "y_pred_rocchio_mm = rocchio_predict(centroids_mm, X_test_mm)\n",
    "acc_rocchio_mm = accuracy_metric(y_test, y_pred_rocchio_mm)\n",
    "print(f\"Acurácia Rocchio: {acc_rocchio_mm:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc226593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 1\n",
    "# C)\n",
    "\n",
    "# Os resultados obtidos na questão 1B mostram que uma aplicação de técnicas de pré-processamento ajudam a melhorar a acurácia dos classificadores NN e Rocchio.\n",
    "# Isso se deve ao fato de que a remoção de outliers e a utilização de valores normalizados reduz o impacto de valores extremos que podem distorcer a análise dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18f24e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== QUESTÃO 2A =====\n",
      "Acurácia NN (implementação própria):  89.9497487437186\n",
      "Acurácia NN (scikit-learn): 89.9497487437186\n"
     ]
    }
   ],
   "source": [
    "# Questão 2\n",
    "# A)\n",
    "\n",
    "import spacy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tweets_path = pathlib.Path().absolute() / 'db' / 'Tweets_Mg.csv'\n",
    "df = pd.read_csv(tweets_path)\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "def embeddings_generator(textos):\n",
    "    embeddings = []\n",
    "    for doc in nlp.pipe(textos, batch_size=50):\n",
    "        embeddings.append(doc.vector)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "print(\"===== QUESTÃO 2A =====\")\n",
    "\n",
    "X = embeddings_generator(df[\"Text\"].astype(str))\n",
    "y = df[\"Classificacao\"].values\n",
    "\n",
    "X_train = X[:8000]\n",
    "y_train = y[:8000]\n",
    "\n",
    "X_test = X[8000:]\n",
    "y_test = y[8000:]\n",
    "\n",
    "y_pred = nn_predict(X_train, y_train, X_test)\n",
    "\n",
    "accuracy = accuracy_metric(y_test, y_pred)\n",
    "print(\"Acurácia NN (implementação própria): \", accuracy)\n",
    "\n",
    "# Agora utilizando o scikit-learn\n",
    "knn = KNeighborsClassifier(n_neighbors=1) # k=5 por padrão, então pra ficar igual à nossa implementação \n",
    "# usamos k=1\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_sklearn = knn.predict(X_test)\n",
    "\n",
    "accuracy_scikit_learn = accuracy_score(y_test, y_pred_sklearn) * 100\n",
    "\n",
    "print(\"Acurácia NN (scikit-learn):\", accuracy_scikit_learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab0e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 2\n",
    "# A) (Continuação)\n",
    "\n",
    "# A acurácia obtida utilizando a implementaçlão manual é igual a utilizando \n",
    "# a biblioteca scikit-learn, pois ambos os métodos utilizam o mesmo algoritmo. A diferença\n",
    "# é que a minha implementação manual foi feita pra utilizar apenas k=1, enquanto a biblioteca\n",
    "# scikit-learn permite escolher o valor de k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 2\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "613b5d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 3\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b02acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 3\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31dbc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 3\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95609a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 4\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac55810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 4\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c535682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 4\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae1c5e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 4\n",
    "# D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23d96387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 5\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "261de58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 5\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9aeee12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 5\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46e765f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 6\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00a32bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 6\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0ef8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 6\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c16ecc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 7\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce54b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 7\n",
    "# B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26946504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 7\n",
    "# C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35025bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 8\n",
    " # Não estou conseguindo acessar o link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f4d1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9cb78594",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### QUESTÕES TEÓRICAS #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2972556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 1\n",
    "# a) “Quanto mais variáveis de entrada forem usadas em um modelo de aprendizado de \n",
    "# máquina, melhor será a qualidade do modelo”. \n",
    "\n",
    "# Resposta: Depende, pois, embora mais variáveis possam fornecer mais informações, \n",
    "# elas também podem conter muitos dados ruidosos, faltantes, ou até mesmo dados irrelevantes, \n",
    "# oque pode fazer com que o modelo aprenda padrões incorretos (overfitting). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "caab68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 1\n",
    "# b) “Independente da qualidade, quanto mais amostras forem obtidas para uma base de \n",
    "# dados, maior a tendência de se obter modelos mais adequados”.\n",
    "\n",
    "# Resposta: Mentira, pois, apesar de mais amostras geralmente ajudarem a melhorar a performance do modelo,\n",
    "# a qualidade dos dados é crucial, pois, dados de baixa qualidade podem introduzir ruído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "105f0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 1\n",
    "# c) “Às vezes com simples manipulações na base de dados (limpeza, conversão de valores, \n",
    "# etc.) pode-se conseguir melhoras significativas nos resultados, sem fazer nenhuma \n",
    "# alteração na técnica de aprendizado de máquina usada”. \n",
    "\n",
    "# Resposta: Verdade, pois, técnicas de pré-processamento de dados pode melhorar a qualidade dos dados,\n",
    "# o que pode levar a melhores resultados sem alterar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50da0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 2\n",
    "\n",
    "# Investimento conservador\n",
    "# Valor Esperado = 30000*0,1 + 5000*0,5 + −10000*0,4\n",
    "# Valor Esperado = 3000 + 2500 − 4000 = 1500\n",
    "\n",
    "# Investimento especulativo\n",
    "# Valor Esperado = 40000*0,1 + 10000*0,5 + −30000*0,4\n",
    "# Valor Esperado = 4000 + 5000 − 12000 = -3000\n",
    "\n",
    "# Investimento cíclico\n",
    "# Valor Esperado = -10000*0,1 + 0*0,5 + 15000*0,4\n",
    "# Valor Esperado = -1000 + 0 + 6000 = 5000\n",
    "\n",
    "# Portanto, o investimento mais apropriado é o cíclico, pois se obtem o maior lucro esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9de3549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questão 3\n",
    "\n",
    "# O desempenho do Random Forest depende do equilíbrio entre a força individual das árvores e a correlação entre elas. \n",
    "# Árvores fortes aumentam a qualidade das decisões, enquanto baixa correlação permite que os erros de uma árvore sejam\n",
    "# compensados pelas outras, resultando em um modelo mais robusto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
